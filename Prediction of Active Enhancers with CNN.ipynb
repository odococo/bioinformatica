{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Active Enhancers with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import os\n",
    "import compress_json\n",
    "from tqdm.auto import tqdm\n",
    "from plot_keras_history import plot_history\n",
    "from barplots import barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### un generator ritorna l'isimo valore di una certa lista, e lo toglie dalla lista. Utili per non tenere in memoria tutti i dati\n",
    "##### es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator():\n",
    "    for i in range(10):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#sto scartano modelli più semplici perché è un problema abbastanza intricato\n",
    "#passo a modelli più complicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import AUC\n",
    "#percettrone per le sequenze\n",
    "perceptron = Sequential([\n",
    "    Input(shape=(200, 4)), #sequenza one-hot encoding, input multi-dimensionale\n",
    "    Flatten(), #reshap dell'input\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "], \"Perceptron\")\n",
    "\n",
    "perceptron.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        AUC(curve=\"PR\", name=\"auprc\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "models.append(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPL come prima\n",
    "mlp = Sequential([\n",
    "    Input(shape=(200, 4)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "], \"MLP\")\n",
    "\n",
    "mlp.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        AUC(curve=\"PR\", name=\"auprc\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "models.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffnn come altra volta però semplificata\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Activation\n",
    "\n",
    "ffnn = Sequential([\n",
    "    Input(shape=(200, 4)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "], \"FFNN\")\n",
    "\n",
    "ffnn.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        AUC(curve=\"PR\", name=\"auprc\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "ffnn.summary()\n",
    "models.append(ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn\n",
    "from tensorflow.keras.layers import Conv2D, Reshape\n",
    "\n",
    "cnn = Sequential([\n",
    "    Input(shape=(200, 4)),\n",
    "    Reshape((200, 4, 1)),\n",
    "    Conv2D(64, kernel_size=(10, 2), activation=\"relu\"), #kernel size è la dimensione della convoluzione\n",
    "    #che ogni neurone fa  (in questo caso sono 64 neuroni) \n",
    "    Conv2D(64, kernel_size=(10, 2), activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(32, kernel_size=(10, 2), strides=(2, 1), activation=\"relu\"), #in questo caso uso lo stride per ridurre la dimensionalità\n",
    "    #dei paramteri. Potrei usare anche un max pooling\n",
    "    Conv2D(32, kernel_size=(10, 1), activation=\"relu\"),\n",
    "    Conv2D(32, kernel_size=(10, 1), activation=\"relu\"), #potrei aggiungere il padding same aggiungendo ,padding=\"same\"\n",
    "    #tenendolo ho davvero tantissimi paramentri! senza il kernel compatta lo spazio dell'input\n",
    "    #se ho un modello molto complesso come l'outer-encoding, è meglio usarlo\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    # questo che segue è un MLP che si mette in coda\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "], \"CNN\")\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        AUC(curve=\"PR\", name=\"auprc\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "cnn.summary()\n",
    "models.append(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM #per GRU bisogna solo importare GRU\n",
    "#long short term memory\n",
    "#composti da SLTM-cell layer particolari che hanno una sorta di ricorrenza\n",
    "#per dati con una certa sequenzialità\n",
    "#molto lento ad apprendere, ma buono nell'accuracy\n",
    "\n",
    "cudnn_lstm = dict(\n",
    "    activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",\n",
    "    recurrent_dropout=0,\n",
    "    unroll=False,\n",
    "    use_bias=True\n",
    ")\n",
    "#è un dizionario di parametri\n",
    "#LSTM è implementato in modo particolare\n",
    "#ed eseguibile su GPU sono con un set di parametri\n",
    "\n",
    "lstm = Sequential([\n",
    "    Input(shape=(200, 4)), #quando prede in pancia questa sequenza\n",
    "    #la cella lstm viene moltiplicata 200 volte. => istantaneamente diventa 200 layer\n",
    "    #molto lente da trainare\n",
    "    LSTM(256, **cudnn_lstm), #si possono concatenare più LSTM\n",
    "    #altri layer LSTM sono i GRU, compromesso tra accuracy e velocità\n",
    "    #altri sono i LMU => tempo di convergenze maggiore. Non ci sono grandi cambiamenti\n",
    "    #per questi bisogna importare LMU_cell da github ma non vale la pena\n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "], \"LSTM\")\n",
    "\n",
    "lstm.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "        AUC(curve=\"PR\", name=\"auprc\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "lstm.summary()\n",
    "models.append(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epigenomic_dataset import load_epigenomes\n",
    "\n",
    "cell_line = \"GM12878\"\n",
    "window_size = 200\n",
    "\n",
    "epigenomes, labels = load_epigenomes(\n",
    "    cell_line = cell_line,\n",
    "    dataset = \"fantom\",\n",
    "    regions = \"enhancers\",\n",
    "    window_size = window_size\n",
    ")\n",
    "\n",
    "epigenomes = epigenomes.droplevel(1, axis=1) \n",
    "labels = labels.values.ravel() #flattate le labels\n",
    "\n",
    "bed = epigenomes.reset_index()[epigenomes.index.names] #estrggo solo i bed (le coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splits = 2\n",
    "holdouts = StratifiedShuffleSplit(n_splits=splits, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucsc_genomes_downloader import Genome\n",
    "from keras_bed_sequence import BedSequence\n",
    "from keras_mixed_sequence import MixedSequence\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "genome = Genome(\"hg19\")\n",
    "\n",
    "def get_holdout(train:np.ndarray, test:np.ndarray, bed:pd.DataFrame, labels:np.ndarray, genome:genome, batch_size=1024)->Tuple[Sequence, Sequence]:\n",
    "    return (\n",
    "        MixedSequence(\n",
    "            x=BedSequence(genome, bed.iloc[train], batch_size=batch_size),\n",
    "            y=labels[train],\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        MixedSequence(\n",
    "            x= BedSequence(genome, bed.iloc[test], batch_size=batch_size),\n",
    "            y=labels[test],\n",
    "            batch_size=batch_size #batch_size maggiori, risultati + veloci\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomputed(results, model:str, holdout:int)->bool:\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        return False\n",
    "    return (\n",
    "        (df.model == model) &\n",
    "        (df.holdout == holdout)\n",
    "    ).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if os.path.exists(\"sequence.json\"):\n",
    " #   results = compress_json.load(\"sequence.json\")\n",
    "#else:\n",
    "results = []\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(holdouts.split(bed, labels)), total=splits, desc=\"Computing holdouts\", dynamic_ncols=True):\n",
    "    train, test = get_holdout(train_index, test_index, bed, labels, genome)\n",
    "    for model in tqdm(models, total=len(models), desc=\"Training models\", leave=False, dynamic_ncols=True):\n",
    "        if precomputed(results, model.name, i):\n",
    "            continue\n",
    "        history = model.fit(\n",
    "            train,\n",
    "            steps_per_epoch=train.steps_per_epoch,\n",
    "            validation_data=test,\n",
    "            validation_steps=test.steps_per_epoch,\n",
    "            epochs=1000,\n",
    "            shuffle=True,\n",
    "            verbose=False,\n",
    "            callbacks=[\n",
    "                EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=50),\n",
    "            ]\n",
    "        ).history\n",
    "        scores = pd.DataFrame(history).iloc[-1].to_dict()\n",
    "        results.append({\n",
    "            \"model\":model.name,\n",
    "            \"run_type\":\"train\",\n",
    "            \"holdout\":i,\n",
    "            **{\n",
    "                key:value\n",
    "                for key, value in scores.items()\n",
    "                if not key.startswith(\"val_\")\n",
    "            }\n",
    "        })\n",
    "        results.append({\n",
    "            \"model\":model.name,\n",
    "            \"run_type\":\"test\",\n",
    "            \"holdout\":i,\n",
    "            **{\n",
    "                key[4:]:value\n",
    "                for key, value in scores.items()\n",
    "                if key.startswith(\"val_\")\n",
    "            }\n",
    "        })\n",
    "      #  compress_json.local(results, \"sequence.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).drop(columns=\"holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplots(\n",
    "    df,\n",
    "    groupby=[\"model\", \"run_type\"],\n",
    "    show_legend=False,\n",
    "    height=5,\n",
    "    orientation=\"horizontal\",\n",
    "    path='barplots/sequence/{feature}.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "for x in glob(\"barplots/sequence/*.png\"):\n",
    "    display(Image.open(x))\n",
    "\n",
    "    #accuracy buona\n",
    "    #AUROC bassa => sbilanciamento delle classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.mean()  #vedo se c'è uno sbilanciamento! non sono a 0.5 \n",
    "#quindi ho le due classi (0,1) sbilanciate!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
