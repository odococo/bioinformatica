{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epigenomic_dataset import load_epigenomes\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# The considered window size\n",
    "window_size = 200\n",
    "cell_line=\"HEK293\"\n",
    "regions=\"enhancers\"\n",
    "\n",
    "# Retrieving the input data\n",
    "X, y = load_epigenomes(\n",
    "    cell_line = cell_line,\n",
    "    dataset = \"fantom\",\n",
    "    regions = regions,\n",
    "    window_size = window_size\n",
    ")\n",
    "\n",
    "y = y.values.ravel()\n",
    "\n",
    "# Imputation of NaN Values\n",
    "X[X.columns] = KNNImputer(n_neighbors=X.shape[0]//10).fit_transform(X)\n",
    "\n",
    "# Robust normalization of the values\n",
    "X[X.columns] = RobustScaler().fit_transform(X)\n",
    "\n",
    "#X = X.values\n",
    "shape=(200,4)\n",
    "#type(X)\n",
    "# Here one should feature selection. How can we do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading chromosomes for genome C:\\\\Users\\\\matte\\\\OneDrive…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from ucsc_genomes_downloader import Genome\n",
    "assembly=r\"C:\\Users\\matte\\OneDrive\\Desktop\\Bioinformatica\\genomes\\hg19\"\n",
    "genome = Genome(assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_bed_sequence import BedSequence\n",
    "\n",
    "def to_bed(data:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"Return bed coordinates from given dataset.\"\"\"\n",
    "    return data.reset_index()[data.index.names]\n",
    "\n",
    "\n",
    "def one_hot_encode(genome:Genome, data:pd.DataFrame, nucleotides:str=\"actg\")->np.ndarray:\n",
    "    return np.array(BedSequence(\n",
    "        genome,\n",
    "        bed=to_bed(data),\n",
    "        nucleotides=nucleotides,\n",
    "        batch_size=1\n",
    "    ))\n",
    "\n",
    "def flat_one_hot_encode(genome:Genome, data:pd.DataFrame, window_size:int, nucleotides:str=\"actg\")->np.ndarray:\n",
    "    return one_hot_encode(genome, data, nucleotides).reshape(-1, window_size*4).astype(int)\n",
    "\n",
    "def to_dataframe(x:np.ndarray, window_size:int, nucleotides:str=\"actg\")->pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        x,\n",
    "        columns = [\n",
    "            f\"{i}{nucleotide}\"\n",
    "            for i in range(window_size)\n",
    "            for nucleotide in nucleotides\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences =  to_dataframe(\n",
    " #       flat_one_hot_encode(genome, X, window_size),\n",
    "  #      window_size\n",
    "  #  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>chromStart</th>\n",
       "      <th>chromEnd</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>839687</td>\n",
       "      <td>839887</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>840711</td>\n",
       "      <td>840911</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>845481</td>\n",
       "      <td>845681</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>855755</td>\n",
       "      <td>855955</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>856613</td>\n",
       "      <td>856813</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65418</th>\n",
       "      <td>chrY</td>\n",
       "      <td>58986666</td>\n",
       "      <td>58986866</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65419</th>\n",
       "      <td>chrY</td>\n",
       "      <td>58994460</td>\n",
       "      <td>58994660</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65420</th>\n",
       "      <td>chrY</td>\n",
       "      <td>59019261</td>\n",
       "      <td>59019461</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65421</th>\n",
       "      <td>chrY</td>\n",
       "      <td>59019818</td>\n",
       "      <td>59020018</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65422</th>\n",
       "      <td>chrY</td>\n",
       "      <td>59025836</td>\n",
       "      <td>59026036</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65423 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom  chromStart  chromEnd strand\n",
       "0      chr1      839687    839887      .\n",
       "1      chr1      840711    840911      .\n",
       "2      chr1      845481    845681      .\n",
       "3      chr1      855755    855955      .\n",
       "4      chr1      856613    856813      .\n",
       "...     ...         ...       ...    ...\n",
       "65418  chrY    58986666  58986866      .\n",
       "65419  chrY    58994460  58994660      .\n",
       "65420  chrY    59019261  59019461      .\n",
       "65421  chrY    59019818  59020018      .\n",
       "65422  chrY    59025836  59026036      .\n",
       "\n",
       "[65423 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences=to_bed(X)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, name: str, model, **kwargs):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def get_model(self) -> Tuple:\n",
    "        return (self.model, self.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def get_decision_tree(name: str = 'DecisionTree', criterion: str = 'gini', max_depth: int = 50, \n",
    "                      random_state: int = 42, class_weight: str = 'balanced', **kwargs) -> Model:\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    return Model(name, model, **kwargs)\n",
    "\n",
    "Model.DecisionTree = get_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTree"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "def get_random_forest(name: str = 'RandomForest', n_estimators: int = 500, criterion: str = 'gini', \n",
    "                      max_depth: int = 30, random_state: int = 42, \n",
    "                      class_weight: str = 'balanced', n_jobs: int = cpu_count, **kwargs):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state,\n",
    "        class_weight=class_weight,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    return Model(name, model, **kwargs)\n",
    "\n",
    "Model.RandomForest = get_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForest"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Flatten, Reshape, Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AlphaDropout, ThresholdedReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def get_sequential(default_name: str = 'Sequential'):\n",
    "    # no first and last layer\n",
    "    def get_layers(*layers: Tuple[Layer]):\n",
    "        def get_model(input_shape: Tuple[int], name: str = None, optimizer: str = 'nadam', \n",
    "                      loss: str = 'binary_crossentropy', metrics: List = None,\n",
    "                      epochs: int = 1000, batch_size: int = 1024, \n",
    "                      validation_split: float = 0.1, shuffle: bool = True, verbose: bool = False, \n",
    "                      callbacks: List = None, **kwargs):\n",
    "            name = name or default_name\n",
    "            input_layer = Input(shape=input_shape)\n",
    "            output_layer = Dense(1, activation=\"sigmoid\")\n",
    "            model = Sequential((input_layer,) + layers + (output_layer,), name)\n",
    "            \n",
    "            metrics = metrics or [\n",
    "                \"accuracy\",\n",
    "                AUC(curve=\"ROC\", name=\"auroc\"),\n",
    "                AUC(curve=\"PR\", name=\"auprc\")\n",
    "            ]\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics\n",
    "            )\n",
    "            \n",
    "            kwargs.update({\n",
    "                'epochs': epochs,\n",
    "                'batch_size': batch_size,\n",
    "                'validation_split': validation_split,\n",
    "                'shuffle': shuffle,\n",
    "                'verbose': verbose,\n",
    "                'callbacks': callbacks\n",
    "            })\n",
    "            model.summary()\n",
    "            return Model(name, model, **kwargs)\n",
    "        return get_model\n",
    "    return get_layers\n",
    "\n",
    "Model.Sequential = get_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 104, 1)            21        \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.Sequential()((104,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.Perceptron = get_sequential('Perceptron')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Perceptron\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.Perceptron((104,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.MLP = get_sequential('MLP') \n",
    "Model.FFNN = get_sequential('FFNN')\n",
    "Model.CNN = get_sequential('CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training 20 sec \n",
    "Model.MLP_Epi = Model.MLP(\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training 40 sec\n",
    "Model.FFNN_Epi = Model.FFNN(\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    Activation(\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test con Alphadropout e ThresholdedReLU\n",
    "Model.FFNN_Epi_2 = Model.FFNN(\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(128),\n",
    "    BatchNormalization(),\n",
    "    ThresholdedReLU(0.05),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    AlphaDropout(0.3), #new\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test con\n",
    "Model.FFNN_Epi_3 = Model.FFNN(\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    ThresholdedReLU(0.05),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    AlphaDropout(0.5), #new\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.MLP_Seq = Model.MLP(\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.FFNN_Seq = Model.FFNN(\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.CNN_Seq = Model.CNN(\n",
    "    Reshape((200, 4, 1)),\n",
    "    Conv2D(64, kernel_size=(10, 2), activation=\"relu\"),\n",
    "    Conv2D(64, kernel_size=(10, 2), activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(32, kernel_size=(10, 2), strides=(2, 1), activation=\"relu\"),\n",
    "    Conv2D(32, kernel_size=(10, 1), activation=\"relu\"),\n",
    "    Conv2D(32, kernel_size=(10, 1), activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucsc_genomes_downloader import Genome\n",
    "from keras_bed_sequence import BedSequence\n",
    "from keras_mixed_sequence import MixedSequence\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "def get_holdout(train:np.ndarray, test:np.ndarray, bed:pd.DataFrame, labels:np.ndarray, genome:genome, batch_size=1024)->Tuple[Sequence, Sequence]:\n",
    "    return (\n",
    "        MixedSequence(\n",
    "            x=BedSequence(genome, bed.iloc[train], batch_size=batch_size),\n",
    "            y=labels[train],\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        MixedSequence(\n",
    "            x= BedSequence(genome, bed.iloc[test], batch_size=batch_size),\n",
    "            y=labels[test],\n",
    "            batch_size=batch_size #batch_size maggiori, risultati + veloci\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splits = 2 #da testare un numero diverso di split\n",
    "holdouts = StratifiedShuffleSplit(n_splits=splits, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, average_precision_score\n",
    "from sanitize_ml_labels import sanitize_ml_labels\n",
    "import numpy as np\n",
    "\n",
    "def report(y_true:np.ndarray, y_pred:np.ndarray)->np.ndarray:\n",
    "    integer_metrics = accuracy_score, balanced_accuracy_score\n",
    "    float_metrics = roc_auc_score, average_precision_score\n",
    "    results1 = {\n",
    "        sanitize_ml_labels(metric.__name__): metric(y_true, np.round(y_pred))\n",
    "        for metric in integer_metrics\n",
    "    }\n",
    "    results2 = {\n",
    "        sanitize_ml_labels(metric.__name__): metric(y_true, y_pred)\n",
    "        for metric in float_metrics\n",
    "    }\n",
    "    return {\n",
    "        **results1,\n",
    "        **results2\n",
    "    }\n",
    "\n",
    "#si usano solo per categorizzazione, non hanno senso per regressione\n",
    "# auroc: area sotto la curva di Receiver operating characteristic: analizza falsi positivi e negativi\n",
    "# valore minimo è 0.5 (non impara niente)  valore massimo è 1 (modello perfetto)\n",
    "# auprc: area sotto la curva di precision recall: va a computare per diversi treashold di precisioni diversi, la somma delle aree\n",
    "#sottese sotto i diversi traingolini della precision-reacall. Un modello che non impara nulla ha AUPRC = 0 e un modello perfetto ha\n",
    "# AUPRC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomputed(results, model:str, holdout:int)->bool:\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        return False\n",
    "    return (\n",
    "        (df.model == model) &\n",
    "        (df.holdout == holdout)\n",
    "    ).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 200, 4, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 191, 3, 64)        1344      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 182, 2, 64)        81984     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 182, 2, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 87, 1, 32)         40992     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 78, 1, 32)         10272     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 69, 1, 32)         10272     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 69, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2208)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                70688     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 216,097\n",
      "Trainable params: 216,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "\n",
    "models.append(Model.CNN_Seq(shape,name=\"CNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('XLA_GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78816058af04360b5b4dc99807b202e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing holdouts', layout=Layout(flex='2'), max=2.0, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e171a04f164efd8e0105f303332de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Rendering sequences in C:\\\\Users\\\\matte\\\\OneDrive\\\\Deskto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-eaf76290902d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Computing holdouts\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_ncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_holdout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training models\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_ncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-40e860b43930>\u001b[0m in \u001b[0;36mget_holdout\u001b[1;34m(train, test, bed, labels, genome, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m     return (\n\u001b[0;32m      9\u001b[0m         MixedSequence(\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_bed_sequence\\bed_sequence.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, assembly, bed, batch_size, verbose, nucleotides, seed, elapsed_epochs, genome_kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;31m# We extract the sequences of the bed file from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;31m# the given genome.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_genome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbed_to_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;31m# We encode the nucleotide sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ucsc_genomes_downloader\\genome.py\u001b[0m in \u001b[0;36mbed_to_sequence\u001b[1;34m(self, bed, chunksize)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mdynamic_ncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                 \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                 \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m             )))\n\u001b[0;32m    518\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    735\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import compress_json\n",
    "#if os.path.exists(\"results1.json\"):\n",
    " #   with open('results.json') as json_file:\n",
    "#        results = json.load(json_file)\n",
    "#else:\n",
    "results = []\n",
    "    \n",
    "for i, (train_index, test_index) in tqdm(enumerate(holdouts.split(sequences, y)), total=splits, desc=\"Computing holdouts\", dynamic_ncols=True):\n",
    "    train, test = get_holdout(train_index, test_index, sequences, y, genome)\n",
    "    for model in tqdm(models, total=len(models), desc=\"Training models\", leave=False, dynamic_ncols=True):\n",
    "        if precomputed(results, model.name, i):\n",
    "            continue\n",
    "        history = model.model.fit(\n",
    "            train,\n",
    "            steps_per_epoch=train.steps_per_epoch,\n",
    "            validation_data=test,\n",
    "            validation_steps=test.steps_per_epoch,\n",
    "            epochs=1000,\n",
    "            shuffle=True,\n",
    "            verbose=False,\n",
    "            callbacks=[\n",
    "                EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=50),\n",
    "            ]\n",
    "        ).history\n",
    "        scores = pd.DataFrame(history).iloc[-1].to_dict()\n",
    "        results.append({\n",
    "            \"model\":model.name,\n",
    "            \"run_type\":\"train\",\n",
    "            \"holdout\":i,\n",
    "            **{\n",
    "                key:value\n",
    "                for key, value in scores.items()\n",
    "                if not key.startswith(\"val_\")\n",
    "            }\n",
    "        })\n",
    "        results.append({\n",
    "            \"model\":model.name,\n",
    "            \"run_type\":\"test\",\n",
    "            \"holdout\":i,\n",
    "            **{\n",
    "                key[4:]:value\n",
    "                for key, value in scores.items()\n",
    "                if key.startswith(\"val_\")\n",
    "            }\n",
    "        })\n",
    "        compress_json.local_dump(results,  f\"results_{cell_line}_{regions}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from barplots import barplots\n",
    "df = pd.DataFrame(results)\n",
    "#df = df.drop(columns=[\"holdout\"])\n",
    "df[:5]\n",
    "\n",
    "\n",
    "barplots(\n",
    "    df,\n",
    "    groupby=[\"model\", \"run_type\"],\n",
    "    show_legend=False,\n",
    "    height=5,\n",
    "    orientation=\"horizontal\"\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "for x in glob(\"barplots/*.png\"):\n",
    "    display(Image.open(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
