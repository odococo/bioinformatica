{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epigenomic_dataset import load_epigenomes\n",
    "from ucsc_genomes_downloader import Genome\n",
    "from keras_bed_sequence import BedSequence\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import entropy\n",
    "from minepy import MINE\n",
    "from boruta import BorutaPy\n",
    "from prince import MFA\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(cell_line: str, dataset: str = \"fantom\", window_size: int = 200) -> Dict[str, pd.DataFrame]:\n",
    "    regions = [\"promoters\", \"enhancers\"]\n",
    "    epigenomes = {}\n",
    "    labels = {}\n",
    "    for region in regions:\n",
    "        epigenome, label = load_epigenomes(\n",
    "            cell_line=cell_line,\n",
    "            dataset=dataset,\n",
    "            regions=region,\n",
    "            window_size=window_size\n",
    "        )\n",
    "        epigenomes.update({region: epigenome})\n",
    "        labels.update({region: label})\n",
    "    return epigenomes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bed(data: pd.DataFrame)-> pd.DataFrame:\n",
    "    \"\"\"Return bed coordinates from given dataset.\"\"\"\n",
    "    return data.reset_index()[data.index.names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome(assembly: str = \"hg19\") -> Genome:\n",
    "    return Genome(assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data: pd.DataFrame, genome: Genome, nucleotides : str = \"actg\", window_size: int = 200)-> np.ndarray:\n",
    "    \"\"\"Set to one only the nucletoide, zero the others\"\"\"\n",
    "    return np.array(BedSequence(\n",
    "        genome,\n",
    "        bed=to_bed(data),\n",
    "        nucleotides=nucleotides,\n",
    "        batch_size=1\n",
    "    )).reshape(-1, window_size * len(nucleotides)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(data: np.ndarray, window_size : int = 200, nucleotides : str = \"actg\")-> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        data,\n",
    "        columns = [\n",
    "            f\"{i}{nucleotide}\"\n",
    "            for i in range(window_size)\n",
    "            for nucleotide in nucleotides\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(epigenomes: np.ndarray, genome: Genome, window_size: int = 200) -> Dict[str, pd.DataFrame]:\n",
    "    {\n",
    "    region: to_dataframe(\n",
    "        one_hot_encode(data, genome, window_size),\n",
    "        window_size\n",
    "    )\n",
    "    for region, data in epigenomes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_retrieval(cell_line: str = 'K562') -> Dict[str, pd.DataFrame]:\n",
    "    global info\n",
    "    print('Downloading data...')\n",
    "    epigenomes, labels = info.get('data') or download_data(cell_line)\n",
    "    info['data'] = (epigenomes, labels)\n",
    "    print('Downloading genome...')\n",
    "    genome = info.get('genome') or get_genome()\n",
    "    info['genome'] = genome\n",
    "    print('Getting dataframe...')\n",
    "    sequences = info.get('sequences') or get_sequences(epigenomes, genome)\n",
    "    info['sequences'] = sequences\n",
    "    print('Finished!')\n",
    "    return epigenomes, labels, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading to datasets/fantom/200/promoters/K562.csv.gz'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading to datasets/fantom/200/enhancers/K562.csv.gz'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading genome...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcf6f58e6f64c9c9e28ef0e83b35990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading chromosomes for genome hg19', layout=Layout(f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a5ebdc14fbfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5262e35536af>\u001b[0m in \u001b[0;36mdata_retrieval\u001b[1;34m(cell_line)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepigenomes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading genome...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgenome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'genome'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_genome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genome'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting dataframe...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-fcac057ae48a>\u001b[0m in \u001b[0;36mget_genome\u001b[1;34m(assembly)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_genome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massembly\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"hg19\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mGenome\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mGenome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massembly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ucsc_genomes_downloader\\genome.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, assembly, chromosomes, filters, verbose, cache_directory)\u001b[0m\n\u001b[0;32m    158\u001b[0m             )\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ucsc_genomes_downloader\\genome.py\u001b[0m in \u001b[0;36m_download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m                     \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                     \u001b[0mdynamic_ncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                     \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 ))\n\u001b[0;32m    298\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    735\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_risk(epigenomes: Dict[str, pd.DataFrame], threshold: int = 1) -> bool:\n",
    "    valid = False\n",
    "    for region, data in epigenomes.items():\n",
    "        rate = data[0] / data[1]\n",
    "        print(f'Rate for {region} is {rate}')\n",
    "        valid = valid or (rate < threshold)\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_check(epigenomes: Dict[str, pd.DataFrame], threshold: int = 10) -> None:\n",
    "    for region, x in epigenomes.items():\n",
    "        print(\"\\n\".join((\n",
    "            f\"Nan values report for {region} data:\",\n",
    "            f\"In the document there are {x.isna().values.sum()} NaN values out of {x.values.size} values.\",\n",
    "            f\"The sample (row) with most values has {x.isna().sum(axis=0).max()} NaN values out of {x.shape[1]} values.\",\n",
    "            f\"The feature (column) with most values has {x.isna().sum().max()} NaN values out of {x.shape[0]} values.\"\n",
    "        )))\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_constant(data: pd.DataFrame, value: int) -> pd.DataFrame:\n",
    "    return df.fillna(value)\n",
    "\n",
    "\n",
    "def fit_media(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return fit_constant(data, data.mean())\n",
    "\n",
    "\n",
    "def fit_median(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return fit_constant(data, data.median())\n",
    "\n",
    "\n",
    "def fit_mode(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return fit_constant(data, data.mode())\n",
    "\n",
    "\n",
    "def fit_neighbours(data: pd.DataFrame, neighbours: int = 5) -> pd.DataFrame:\n",
    "    return pd.DataFrame(KNNImputer(n_neighbours=neighbours).fit_transform(data.values), \n",
    "                        columns=data.columns,\n",
    "                        index=data.index\n",
    "                       )\n",
    "\n",
    "\n",
    "def fit_missing(epigenomes: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    for region, data in epigenomes.items():\n",
    "        epigenomes[region] = fit_neighbours(data)\n",
    "    return epigenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_balance(labels: Dict[str, pd.DataFrame]) -> None:\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "    for axis, (region, y) in zip(axes.ravel(), labels.items()):\n",
    "        y.hist(ax=axis, bins=3)\n",
    "        axis.set_title(f\"Classes count in {region}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constant_features(epigenomes: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    def drop(df:pd.Dataframe) -> pd.DataFrame:\n",
    "        return df.loc[:, (df != df.iloc[0]).any()]\n",
    "    for region, data in epigenomes.items():\n",
    "        result = drop_constant_features(data)\n",
    "        if data.shape[1] != result.shape[1]:\n",
    "            print(f\"Features in {region} were constant and had to be dropped!\")\n",
    "            epigenomes[region] = result\n",
    "        else:\n",
    "            print(f\"No constant features were found in {region}!\")\n",
    "    return epigenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_z_scoring(epigenomes: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    def robust_zscoring(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pd.DataFrame(\n",
    "            RobustScaler().fit_transform(df.values),\n",
    "            columns=df.columns,\n",
    "            index=df.index\n",
    "        )\n",
    "    return {region: robust_zscoring(data) for region, data in epigenomes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_uncorrelated(epigenomes: Dict[str, pd.DataFrame], p_value_threshold: float = 0.01, correlation_threshold: float = 0.05) -> Dict[str, pd.DataFrame]:\n",
    "    uncorrelated = {region: set() for region in epigenomes}\n",
    "    \n",
    "    def pearson():\n",
    "        for region, data in epigenomes.items():\n",
    "            for column in tqdm(data.columns, desc=f\"Running Pearson test for {region}\", dynamic_ncols=True, leave=False):\n",
    "                correlation, p_value = pearsonr(data[column].values.ravel(), labels[region].values.ravel())\n",
    "                if p_value > p_value_threshold:\n",
    "                    print(region, column, correlation)\n",
    "                    uncorrelated[region].add(column)\n",
    "    \n",
    "    def spearman():\n",
    "        for region, data in epigenomes.items():\n",
    "            for column in tqdm(data.columns, desc=f\"Running Spearman test for {region}\", dynamic_ncols=True, leave=False):\n",
    "                correlation, p_value = spearmanr(data[column].values.ravel(), labels[region].values.ravel())\n",
    "                if p_value > p_value_threshold:\n",
    "                    print(region, column, correlation)\n",
    "                uncorrelated[region].add(column)\n",
    "    \n",
    "    def mine():\n",
    "        for column in tqdm(uncorrelated[region], desc=f\"Running MINE test for {region}\", dynamic_ncols=True, leave=False):\n",
    "            mine = MINE()\n",
    "            mine.compute_score(x[column].values.ravel(), labels[region].values.ravel())\n",
    "            score = mine.mic()\n",
    "            if score < correlation_threshold:\n",
    "                print(region, column, score)\n",
    "            else:\n",
    "                uncorrelated[region].remove(column)\n",
    "                \n",
    "    def drop():\n",
    "        for region, data in epigenomes.items():\n",
    "            epigenomes[region] = data.drop(columns=[col for col in uncorrelated[region] if col in x.columns])\n",
    "        return epigenomes\n",
    "                \n",
    "    pearson()\n",
    "    spearman()\n",
    "    mine()\n",
    "    return drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_too_correlated(epigenomes: Dict[str, pd.DataFrame], p_value_threshold: float = 0.01, correlation_threshold: float = 0.95) -> Dict[str, pd.DataFrame]:\n",
    "    extremely_correlated = {region: set() for region in epigenomes}\n",
    "    scores = {region: [] for region in epigenomes}\n",
    "    \n",
    "    def pearson():\n",
    "        for region, x in epigenomes.items():\n",
    "            for i, column in tqdm(\n",
    "                    enumerate(x.columns),\n",
    "                    total=len(x.columns), \n",
    "                    desc=f\"Running Pearson test for {region}\", \n",
    "                    dynamic_ncols=True, \n",
    "                    leave=False):\n",
    "                for feature in x.columns[i+1:]:\n",
    "                    correlation, p_value = pearsonr(x[column].values.ravel(), x[feature].values.ravel())\n",
    "                    correlation = np.abs(correlation)\n",
    "                    scores[region].append((correlation, column, feature))\n",
    "                    if p_value < p_value_threshold and correlation > correlation_threshold:\n",
    "                        print(region, column, feature, correlation)\n",
    "                        if entropy(x[column]) > entropy(x[feature]):\n",
    "                            extremely_correlated[region].add(feature)\n",
    "                        else:\n",
    "                            extremely_correlated[region].add(column)\n",
    "                        \n",
    "    return {region: sorted(score, key=lambda x: np.abs(x[0]), reverse=True) for region, score in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(epigenomes: Dict[str, pd.DataFrame], scores: Dict[str, List[Tuple]]):\n",
    "    def get_data(region:str, how_many: int, from_start: bool = True) -> List[str]:\n",
    "        data = scores[region][:how_many] if from_start else scores[region][-how_many:]\n",
    "        data = list(zip(data))[1:]\n",
    "        columns = list(set([column for row in data for column in row]))\n",
    "        return columns\n",
    "    \n",
    "    def plot(how_many: int, correlated: bool) -> None:\n",
    "        for region, data in epigenomes.items():\n",
    "            print(f\"Most {'correlated' if correlated else 'uncorrelated'} features from {region} epigenomes\")\n",
    "            sns.pairplot(pd.concat([\n",
    "                x[get_data(region, how_many, correlated)],\n",
    "                labels[region],\n",
    "            ], axis=1), hue=labels[region].columns[0])\n",
    "            plt.show()\n",
    "    \n",
    "    def correlated(how_many: int):\n",
    "        plot(how_many, True)\n",
    "        \n",
    "    def uncorrelated(how_many: int):\n",
    "        plot(how_many, False)\n",
    "        \n",
    "    def get_top_most_different(dist, n: int):\n",
    "        return np.argsort(-np.mean(dist, axis=1).flatten())[:n]\n",
    "    \n",
    "    def get_top_most_different_tuples(dist, n: int):\n",
    "        return list(zip(*np.unravel_index(np.argsort(-dist.ravel()), dist.shape)))[:n]\n",
    "        \n",
    "    def most_different_features(top_number: int) -> None:\n",
    "        for region, x in epigenomes.items():\n",
    "            dist = euclidean_distances(x.T)\n",
    "            most_distance_columns_indices = get_top_most_different(dist, top_number)\n",
    "            columns = x.columns[most_distance_columns_indices]\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(25, 5))\n",
    "            print(f\"Top {top_number} different features from {region}.\")\n",
    "            for column, axis in zip(columns, axes.flatten()):\n",
    "                head, tail = x[column].quantile([0.05, 0.95]).values.ravel()\n",
    "\n",
    "                mask = ((x[column] < tail) & (x[column] > head)).values\n",
    "\n",
    "                cleared_x = x[column][mask]\n",
    "                cleared_y = labels[region].values.ravel()[mask]\n",
    "\n",
    "                cleared_x[cleared_y==0].hist(ax=axis, bins=20)\n",
    "                cleared_x[cleared_y==1].hist(ax=axis, bins=20)\n",
    "\n",
    "                axis.set_title(column)\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    def most_different_tuples(top_number: int) -> None:\n",
    "        for region, x in epigenomes.items():\n",
    "            dist = euclidean_distances(x.T)\n",
    "            dist = np.triu(dist)\n",
    "            tuples = get_top_most_different_tuples(dist, top_number)\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(25, 5))\n",
    "            print(f\"Top {top_number} different tuples of features from {region}.\")\n",
    "            for (i, j), axis in zip(tuples, axes.flatten()):\n",
    "                column_i = x.columns[i]\n",
    "                column_j = x.columns[j]\n",
    "                for column in (column_i, column_j):\n",
    "                    head, tail = x[column].quantile([0.05, 0.95]).values.ravel()\n",
    "                    mask = ((x[column] < tail) & (x[column] > head)).values\n",
    "                    x[column][mask].hist(ax=axis, bins=20, alpha=0.5)\n",
    "                axis.set_title(f\"{column_i} and {column_j}\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "    correlated(3)\n",
    "    uncorrelated(3)\n",
    "    most_different_features(5)\n",
    "    most_different_tuples(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis (selection and decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_with_boruta(epigenomes: Dict[str, pd.DataFrame], labels: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    def get_features_filter(data: pd.DataFrame, label: pd.DataFrame, name: str) -> BorutaPy:\n",
    "        boruta_selector = BorutaPy(\n",
    "            RandomForestClassifier(n_jobs=cpu_count(), class_weight='balanced', max_depth=5),\n",
    "            n_estimators='auto',\n",
    "            verbose=2,\n",
    "            alpha=0.05, # p_value\n",
    "            max_iter=10, # In practice one would run at least 100-200 times\n",
    "            random_state=42\n",
    "        )\n",
    "        boruta_selector.fit(data.values, label.values.ravel())\n",
    "        return boruta_selector\n",
    "\n",
    "    return {\n",
    "        region: get_features_filter(\n",
    "            data=data,\n",
    "            label=labels[region],\n",
    "            name=f\"{cell_line}/{region}\"\n",
    "        ).transform(data.values)\n",
    "        for region, data in tqdm(\n",
    "            epigenomes.items(),\n",
    "            desc=\"Running Baruta Feature estimation\"\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(epigenomes: Dict[str, pd.DataFrame]):\n",
    "    def check_tasks(xs, ys, titles: List[str]) -> Tuple:\n",
    "        assert len(xs) == len(ys) == len(titles)\n",
    "        for x, y in zip(xs, ys):\n",
    "            assert x.shape[0] == y.shape[0]\n",
    "        return xs, ys, titles\n",
    "    \n",
    "    tasks = {\n",
    "        \"x\":[\n",
    "            *[\n",
    "                val.values\n",
    "                for val in epigenomes.values()\n",
    "            ],\n",
    "            *[\n",
    "                val.values\n",
    "                for val in sequences.values()\n",
    "            ],\n",
    "            pd.concat(sequences.values()).values,\n",
    "            pd.concat(sequences.values()).values,\n",
    "            *[\n",
    "                np.hstack([\n",
    "                    pca(epigenomes[region], n_components=25),\n",
    "                    mfa(sequences[region], n_components=25)\n",
    "                ])\n",
    "                for region in epigenomes\n",
    "            ]\n",
    "        ],\n",
    "        \"y\":[\n",
    "            *[\n",
    "                val.values.ravel()\n",
    "                for val in labels.values()\n",
    "            ],\n",
    "            *[\n",
    "                val.values.ravel()\n",
    "                for val in labels.values()\n",
    "            ],\n",
    "            pd.concat(labels.values()).values.ravel(),\n",
    "            np.vstack([np.ones_like(labels[\"promoters\"]), np.zeros_like(labels[\"enhancers\"])]).ravel(),\n",
    "            *[\n",
    "                val.values.ravel()\n",
    "                for val in labels.values()\n",
    "            ],\n",
    "        ],\n",
    "        \"titles\":[\n",
    "            \"Epigenomes promoters\",\n",
    "            \"Epigenomes enhancers\",\n",
    "            \"Sequences promoters\",\n",
    "            \"Sequences enhancers\",\n",
    "            \"Sequences active regions\",\n",
    "            \"Sequences regions types\",\n",
    "            \"Combined promoters data\",\n",
    "            \"Combined enhancers data\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return check_tasks(tasks['x'], tasks['y'], tasks['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decomposed_data(xs, ys, titles):\n",
    "    colors = np.array([\n",
    "        \"tab:blue\",\n",
    "        \"tab:orange\",\n",
    "    ])\n",
    "    \n",
    "    def pca(data: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "        return PCA(n_components=n_components, random_state=42).fit_transform(data)\n",
    "\n",
    "    def mfa(data: pd.DataFrame, n_components : int = 2, nucleotides : str = 'actg') -> np.ndarray:\n",
    "        return MFA(groups={\n",
    "            nucleotide: [\n",
    "                column\n",
    "                for column in data.columns\n",
    "                if nucleotide in column\n",
    "            ]\n",
    "            for nucleotide in nucleotides\n",
    "        }, n_components=n_components, random_state=42).fit_transform(data)\n",
    "    \n",
    "    def sklearn_tsne(x: np.ndarray, perplexity: int, dimensionality_threshold: int = 50):\n",
    "        if x.shape[1] > dimensionality_threshold:\n",
    "            x = pca(x, n_components=dimensionality_threshold)\n",
    "        return STSNE(perplexity=perplexity, n_jobs=cpu_count(), random_state=42).fit_transform(x)\n",
    "    \n",
    "    def ulyanov_tsne(x: np.ndarray, perplexity: int, dimensionality_threshold: int = 50, n_components: int = 2):\n",
    "        if x.shape[1] > dimensionality_threshold:\n",
    "            x = pca(x, n_components=dimensionality_threshold)\n",
    "        return UTSNE(n_components=n_components, perplexity=perplexity, n_jobs=cpu_count(), random_state=42, verbose=True).fit_transform(x)\n",
    "    \n",
    "    def cannylab_tsne(x: np.ndarray, perplexity: int, dimensionality_threshold: int = 50):\n",
    "        if x.shape[1] > dimensionality_threshold:\n",
    "            x = pca(x, n_components=dimensionality_threshold)\n",
    "        return CTSNE(perplexity=perplexity, random_seed=42).fit_transform(x)\n",
    "    \n",
    "    def nystroem(x:np.array)->np.array:\n",
    "        return Nystroem(random_state=42, n_components=300).fit_transform(x)\n",
    "\n",
    "    def monte_carlo(x:np.array)->np.array:\n",
    "        return RBFSampler(random_state=42, n_components=300).fit_transform(x)\n",
    "\n",
    "    def linear(x:np.array)->np.array:\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decomposed_data():\n",
    "    def show_pca():\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(32, 16))\n",
    "        for x, y, title, axis in tqdm(zip(xs, ys, titles, axes.flatten()), desc=\"Computing PCAs\", total=len(xs)):\n",
    "            axis.scatter(*pca(x).T, s=1, color=colors[y])\n",
    "            axis.xaxis.set_visible(False)\n",
    "            axis.yaxis.set_visible(False)\n",
    "            axis.set_title(f\"PCA decomposition - {title}\")\n",
    "        plt.show()\n",
    "        \n",
    "    def show_tsne():\n",
    "        for perpexity in tqdm((30, 40, 50, 100, 500, 5000), desc=\"Running perplexities\"):\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(40, 20))\n",
    "            for x, y, title, axis in tqdm(zip(xs, ys, titles, axes.flatten()), desc=\"Computing TSNEs\", total=len(xs)):\n",
    "                axis.scatter(*cannylab_tsne(x, perplexity=perpexity).T, s=1, color=colors[y])\n",
    "                axis.xaxis.set_visible(False)\n",
    "                axis.yaxis.set_visible(False)\n",
    "                axis.set_title(f\"TSNE decomposition - {title}\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
